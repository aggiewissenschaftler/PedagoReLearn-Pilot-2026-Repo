# PedagoReLearn


**Â© 2025 Thomas F. Hallmark**  
Licensed under the [MIT License](LICENSE)

---

## ðŸŒ Overview

**PedagoReLearn** is an **AI-driven reinforcement learning (RL) framework** for adaptive cross-cultural tutoring.  
It models cultural competence training as a *stateâ€“actionâ€“reward* process where an agent learns when to **teach**, **review**, or **quiz** learners across domains such as etiquette, privacy, work, and travel.

Grounded in **John Deweyâ€™s progressive education theory**, the system demonstrates how pedagogical strategies can *emerge autonomously through experience*, advancing long-term mastery and retention.

---

## ðŸŽ“ Project Summary

PedagoReLearn formulates tutoring as a **Markov Decision Process (MDP)**:

| Component | Description |
|------------|-------------|
| **States** | Learner mastery levels and recency of review for each cultural rule |
| **Actions** | `teach`, `quiz`, `review`, or `no-op` (pause) |
| **Rewards** | Reflect learning success, retention, and teaching efficiency |

Each YAML file under `/rules/` defines a **cultural knowledge domain** (e.g., workplace etiquette, travel behavior, hygiene norms).  
The **Gymnasium environment** (`pedagorelearn_env.py`) interprets these as interactive learning topics.

---

## ðŸ“ Repository Structure
```
PedagoReLearn/
â”‚
â”œâ”€â”€ agents/                         # RL agent implementations
â”‚   â”œâ”€â”€ sarsa_agent.py              # SARSA(0) on-policy learner
â”‚   â””â”€â”€ random_agent.py             # Random baseline policy
â”‚
â”œâ”€â”€ archive/                        # Backup versions & logs
â”‚
â”œâ”€â”€ docs/                           # Proposals, outlines, and references
â”‚   â”œâ”€â”€ Proposal - PedagoReLearn.pdf
â”‚   â”œâ”€â”€ Outline R5 - Project Proposal (with Dewey).docx
â”‚   â””â”€â”€ README_German_Cultural_Rules_Handbook_Final.pdf
â”‚
â”œâ”€â”€ experiments/                    # Experimental scripts
â”‚   â”œâ”€â”€ compare_sarsa_versions.py
â”‚   â”œâ”€â”€ analyze_csv.py
â”‚   â””â”€â”€ analyze_runs.py
â”‚
â”œâ”€â”€ plots/                          # Generated performance figures
â”‚
â”œâ”€â”€ results/                        # CSV output files by seed/run
â”‚
â”œâ”€â”€ rules/                          # YAML cultural knowledge base
â”‚   â”œâ”€â”€ work_professional.yaml
â”‚   â”œâ”€â”€ transport_travel.yaml
â”‚   â”œâ”€â”€ digital_privacy.yaml
â”‚   â”œâ”€â”€ religion_customs.yaml
â”‚   â”œâ”€â”€ economy_society.yaml
â”‚   â”œâ”€â”€ hygiene.yaml
â”‚   â”œâ”€â”€ emergency_legal.yaml
â”‚   â””â”€â”€ â€¦
â”‚
â”œâ”€â”€ trace_results/                  # Training logs and evaluation data
â”‚   â”œâ”€â”€ cultural_rule_validator.py
â”‚   â””â”€â”€ â€¦
â”‚
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ pedagorelearn_env.py            # Core Gymnasium environment
â”œâ”€â”€ rules_loader.py                 # YAML rule loader and validator
â”‚
â”œâ”€â”€ student_model_sarsa.py          # Simulated student model
â”œâ”€â”€ student_model_complete.py       # Extended learner model (alt.)
â”‚
â”œâ”€â”€ train_runner.py                 # Training control script
â”œâ”€â”€ train_eval.py                   # Evaluation & comparison logic
â”‚
â”œâ”€â”€ tutor_train_sarsa_rewarded.py   # Main SARSA training driver
â”œâ”€â”€ tutor_baselines.py              # Baseline policies
â”œâ”€â”€ run_training.sh                 # Shell automation script
â””â”€â”€ plot_trace_results.py           # Visualization utilities
```
---

## âš™ï¸ Quick Start

```bash
# 1. Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate        # macOS/Linux
# .venv\Scripts\activate          # Windows

# 2. Install dependencies
pip install -r requirements.txt

# 3. Train SARSA agent
python tutor_train_sarsa_rewarded.py

# 4. Analyze or visualize results
python plot_trace_results.py
python compare_sarsa_versions.py

---

Expected Output Example

Episode 500 | Avg reward = 118.6 | Steps-to-mastery = 47 | Accuracy = 0.91
Aggregated policy surpasses fixed curriculum baseline.

ðŸ§  Tech Stack
	â€¢	Python 3.10+
	â€¢	Gymnasium â‰¥ 0.29
	â€¢	NumPy â‰¥ 1.23
	â€¢	Matplotlib â‰¥ 3.7
	â€¢	PyYAML for rule parsing and validation

â¸»

ðŸš€ Current Progress
	â€¢	âœ… Full Gymnasium-compliant environment with stochastic student model
	â€¢	âœ… Reward shaping, mastery tracking, and forgetting dynamics verified
	â€¢	âœ… Functional SARSA(0) agent with Îµ-greedy exploration
	â€¢	âœ… Aggregation and baseline comparison scripts tested
	â€¢	âœ… Week-by-week reproducible results stored under /results/

Next steps: aggregation ablations, statistical analysis, and documentation polish for final submission.

â¸»

ðŸ”¬ Future Directions
	â€¢	Full aggregation ablation across four schemes
	â€¢	Sensitivity analysis for Î±, Î³, and Îµ-decay parameters
	â€¢	Integration of heuristic spaced-repetition baseline
	â€¢	Policy interpretability visualization (heatmaps, frequency plots)
	â€¢	Expansion to additional cultural domains and learner models
	
	ðŸ™ Acknowledgments

Developed for CSCE 642: Reinforcement Learning (Fall 2025)
**Texas A&M University**

Conceptual design and implementation by **Thomas F. Hallmark** and **Jun Kwon**.
>**AUTHOR BIOGRAPHIES**
>
> **Hallmark, T. F. (2025).** | thomas.hallmark@tamu.edu
>
>Thomas F. Hallmark is a doctoral student in Curriculum and Instruction with a cognate in Engineering Education in the Department of Teaching, Learning, and Culture at Texas A&M University. He holds degrees in Legal Studies and Business Administration (MBA) and brings more than 30 years of experience in the nuclear and utilities industries. His research focuses on the integration of artificial intelligence and reinforcement learning in engineering and STEM education, emphasizing adaptive tutoring systems, veteran transitions, and cross-cultural learning. Hallmarkâ€™s work combines pedagogical theory with computational modeling to design human-centered AI learning environments.
>
> **Kwon, J. (2025).**
>
>Jun Kwon is a graduate student in Computer Science and Engineering at Texas A&M University, specializing in machine learning and artificial intelligence applications for education and human-computer interaction. His research interests include reinforcement learning algorithms, neural network optimization, and adaptive feedback mechanisms in educational software. Kwon contributes to the computational architecture and algorithmic implementation of PedagoReLearn, focusing on model design, environment development, and performance evaluation across multiple RL frameworks.
> 
>> **Joint Contribution**
>Hallmark and Kwon collaboratively developed the conceptual framework and technical implementation of PedagoReLearn, merging educational theory and AI engineering to advance research in adaptive tutoring systems and cultural-learning reinforcement models.

â¸»

ðŸ“œ GitHub Description

Adaptive RL tutoring system modeling cultural learning through Dewey-inspired state, action, and reward design.

â¸»

ðŸ¤– AI Use Disclaimer

Artificial intelligence (AI) toolsâ€”including ChatGPTâ€”were used only for grammar, formatting, and document organization.
All intellectual content (code, methodology, analysis) is the original work of the authors and complies with Texas A&M University academic integrity standards.


